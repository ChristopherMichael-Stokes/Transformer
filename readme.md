My attempt at a from-scratch PyTorch implementation of the Transformer model from the seminal 2017 paper 'Attention Is All You Need'


Add reference to paper here